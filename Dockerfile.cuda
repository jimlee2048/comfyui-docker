FROM python:3.12-slim AS comfyui-helper-builder
WORKDIR /build
COPY pyproject.toml ./
COPY src ./src
RUN pip install --no-cache-dir --upgrade pip build \
    && python -m build --wheel --outdir dist

FROM nvidia/cuda:13.0.1-cudnn-runtime-ubuntu24.04

ENV WORKDIR=/workspace
WORKDIR ${WORKDIR}
ENV COMFYUI_PATH=${WORKDIR}/ComfyUI
ENV COMFYUI_MN_PATH=${COMFYUI_PATH}/custom_nodes/comfyui-manager

ARG DEBIAN_FRONTEND=noninteractive
RUN --mount=type=cache,target=/var/cache/apt \
    apt-get update \
    && apt-get upgrade -y \
    && apt-get install -y --no-install-recommends \
    python3.12-full python3.12-dev python3-pip tini jq ca-certificates git build-essential cmake ninja-build wget curl aria2 ffmpeg libgl1-mesa-dev libopengl0 \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# prepare python environment
## create venv
RUN python3 -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
## write venv to .bashrc
RUN echo "source /opt/venv/bin/activate" >> ~/.bashrc
## let .pyc files be stored in one place
ENV PYTHONPYCACHEPREFIX="/root/.cache/pycache"
## add pytorch index url to pip config
ARG PYTORCH_INDEX_URL="https://download.pytorch.org/whl/cu130"
ENV PIP_EXTRA_INDEX_URL=${PYTORCH_INDEX_URL}
## upgrade pip, setuptools, wheel
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install -U pip setuptools wheel

# install comfyui
RUN git clone --single-branch https://github.com/comfyanonymous/ComfyUI.git ${COMFYUI_PATH} \
    && git clone --single-branch https://github.com/Comfy-Org/ComfyUI-Manager.git ${COMFYUI_MN_PATH}

# master(nightly), or version tag like v0.1.0
# https://github.com/comfyanonymous/ComfyUI/tags
ARG COMFYUI_VERSION=master
RUN git -C ${COMFYUI_PATH} fetch --all --tags --prune \
    && git -C ${COMFYUI_PATH} reset --hard ${COMFYUI_VERSION}
# main(nightly), or version tag like v0.1.0
# https://github.com/ltdrdata/ComfyUI-Manager/tags
ARG COMFYUI_MN_VERSION=main
RUN git -C ${COMFYUI_MN_PATH} reset --hard ${COMFYUI_MN_VERSION}

# install pytorch latest
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install \
    torch==2.9 torchvision torchaudio --index-url ${PYTORCH_INDEX_URL}

# install comfyui basic requirements
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install \
    -r ${COMFYUI_PATH}/requirements.txt \
    -r ${COMFYUI_MN_PATH}/requirements.txt

# install triton
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install triton --index-url ${PYTORCH_INDEX_URL}

# xformers not yet support torch 2.9 & cuda 13.0 officially, disable for now, see: https://github.com/facebookresearch/xformers/pull/1344
## install xformers
# RUN --mount=type=cache,target=/root/.cache/pip \
#     pip install xformers --index-url ${PYTORCH_INDEX_URL}

# install nunchaku
RUN --mount=type=cache,target=/root/.cache/pip \
    # NUNCHAKU_VERSION=$(curl -s https://api.github.com/repos/nunchaku-tech/nunchaku/releases/latest | jq -r '.tag_name') \
    # ComfyUI-nunchaku not yet support nunchaku>1.0.0, pin to v1.0.0 for now
    NUNCHAKU_VERSION=v1.0.0 \
    && pip install -U "https://github.com/nunchaku-tech/nunchaku/releases/download/${NUNCHAKU_VERSION}/nunchaku-${NUNCHAKU_VERSION#v}+torch2.9-cp312-cp312-linux_x86_64.whl"

# install sageattention2
RUN --mount=type=cache,target=/root/.cache/pip \
    SAGEATTN_VERSION=$(curl -s https://api.github.com/repos/jimlee2048/SageAttention/releases/latest | jq -r '.tag_name') \
    && pip install -U "https://github.com/jimlee2048/SageAttention/releases/download/${SAGEATTN_VERSION}/sageattention-${SAGEATTN_VERSION#v}+cu130torch2.9-cp39-abi3-linux_x86_64.whl"

# install custom extra pip packages, if you don't mind image size
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install \
    # to avoid possible incompatibility
    "numpy<2" \
    pyopengl pyopengl-accelerate \
    onnx onnxruntime onnxruntime-gpu \
    transformers diffusers accelerate \
    # i hate this stupid solution to avoid possible conflict :(
    opencv-python opencv-python-headless opencv-contrib-python opencv-contrib-python-headless \
    huggingface_hub \
    nvitop

# install helper package without keeping source tree in the image
COPY --from=comfyui-helper-builder /build/dist /tmp/helper-dist
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install /tmp/helper-dist/*.whl \
    && rm -rf /tmp/helper-dist

VOLUME [ "${COMFYUI_PATH}/user", "${COMFYUI_PATH}/output" , "${COMFYUI_PATH}/models", "${COMFYUI_PATH}/custom_nodes"]
EXPOSE 8188
# use tini as entrypoint to handle signals properly
ENTRYPOINT [ "/usr/bin/tini", "--" ]
CMD [ "comfyui-boot" ]
